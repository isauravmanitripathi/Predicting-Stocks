{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Reading the saved data pickle file\n",
    "df_stocks = pd.read_pickle('Stock_Market_Prediction-master/Data/Pickled ten year filtered data (Articles + DJIA).pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_stocks['prices'] = df_stocks['adj close'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# selecting the prices and articles\n",
    "df_stocks = df_stocks[['prices', 'articles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stocks['articles'] = df_stocks['articles'].map(lambda x: x.lstrip('.-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_stocks[['prices']].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding new columns to the data frame\n",
    "df[\"compound\"] = ''\n",
    "df[\"neg\"] = ''\n",
    "df[\"neu\"] = ''\n",
    "df[\"pos\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import unicodedata\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for date, row in df_stocks.T.iteritems():\n",
    "    try:\n",
    "        sentence = unicodedata.normalize('NFKD', df_stocks.loc[date, 'articles']).encode('ascii','ignore')\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        df.set_value(date, 'compound', ss['compound'])\n",
    "        df.set_value(date, 'neg', ss['neg'])\n",
    "        df.set_value(date, 'neu', ss['neu'])\n",
    "        df.set_value(date, 'pos', ss['pos'])\n",
    "    except TypeError:\n",
    "        print df_stocks.loc[date, 'articles']\n",
    "        print date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentence = 'paris shootout police officer suspected guman dead'\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# import unicodedata\n",
    "# sid = SentimentIntensityAnalyzer()\n",
    "# ss = sid.polarity_scores(sentence)\n",
    "# ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking date for empty strings\n",
    "# for date, row in df_stocks.T.iteritems():\n",
    "#     if type(df_stocks.loc[date, 'articles']).__name__ == 'str':\n",
    "#         print date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_start_date = '2007-01-01'\n",
    "train_end_date = '2014-12-31'\n",
    "test_start_date = '2015-01-01'\n",
    "test_end_date = '2016-12-31'\n",
    "train = df.ix[train_start_date : train_end_date]\n",
    "test = df.ix[test_start_date:test_end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_score_list = []\n",
    "for date, row in train.T.iteritems():\n",
    "    #sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "    sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "numpy_df_train = np.asarray(sentiment_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_score_list = []\n",
    "for date, row in test.T.iteritems():\n",
    "    #sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "    sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "numpy_df_test = np.asarray(sentiment_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(train['prices'])\n",
    "y_test = pd.DataFrame(test['prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(numpy_df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction, bias, contributions = ti.predict(rf, numpy_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = pd.date_range(test_start_date, test_end_date)\n",
    "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predictions_df.plot() \n",
    "#test['prices'].plot()\n",
    "\n",
    "predictions_plot = predictions_df.plot()\n",
    "\n",
    "fig = y_test.plot(ax = predictions_plot).get_figure()\n",
    "fig.savefig(\"graphs/random forest without smoothing.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = predictions_df.rename(columns={\"prices\": \"predicted_price\"}).plot(title='Random Forest predicted prices 8-2 years')\n",
    "ax.set_xlabel(\"Dates\")\n",
    "ax.set_ylabel(\"Stock Prices\")\n",
    "fig = y_test.rename(columns={\"prices\": \"actual_price\"}).plot(ax = ax).get_figure()\n",
    "fig.savefig(\"graphs/random forest without smoothing.png\")\n",
    "\n",
    "# colors = ['332288', '88CCEE', '44AA99', '117733', '999933', 'DDCC77', 'CC6677', '882255', 'AA4499']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing the prices by a constant value so that it represents closing price during the testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "temp_date = test_start_date\n",
    "average_last_5_days_test = 0\n",
    "total_days = 10\n",
    "for i in range(total_days):\n",
    "    average_last_5_days_test += test.loc[temp_date, 'prices']\n",
    "    # Converting string to date time\n",
    "    temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "    # Reducing one day from date time\n",
    "    difference = temp_date + timedelta(days=1)\n",
    "    # Converting again date time to string\n",
    "    temp_date = difference.strftime('%Y-%m-%d')\n",
    "    #print temp_date\n",
    "average_last_5_days_test = average_last_5_days_test / total_days\n",
    "print average_last_5_days_test\n",
    "\n",
    "temp_date = test_start_date\n",
    "average_upcoming_5_days_predicted = 0\n",
    "for i in range(total_days):\n",
    "    average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "    # Converting string to date time\n",
    "    temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "    # Adding one day from date time\n",
    "    difference = temp_date + timedelta(days=1)\n",
    "    # Converting again date time to string\n",
    "    temp_date = difference.strftime('%Y-%m-%d')\n",
    "    print temp_date\n",
    "average_upcoming_5_days_predicted = average_upcoming_5_days_predicted / total_days\n",
    "print average_upcoming_5_days_predicted\n",
    "#average train.loc['2013-12-31', 'prices'] - advpredictions_df.loc['2014-01-01', 'prices']\n",
    "difference_test_predicted_prices = average_last_5_days_test - average_upcoming_5_days_predicted\n",
    "print difference_test_predicted_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding 6177 to all the advpredictions_df price values\n",
    "predictions_df['prices'] = predictions_df['prices'] + difference_test_predicted_prices\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = predictions_df.rename(columns={\"prices\": \"predicted_price\"}).plot(title='Random Forest predicted prices 8-2 years after aligning')\n",
    "ax.set_xlabel(\"Dates\")\n",
    "ax.set_ylabel(\"Stock Prices\")\n",
    "fig = y_test.rename(columns={\"prices\": \"actual_price\"}).plot(ax = ax).get_figure()\n",
    "fig.savefig(\"graphs/random forest with aligning.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing the time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying EWMA pandas to smooth the stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df['ewma'] = pd.ewma(predictions_df[\"prices\"], span=60, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df['actual_value'] = test['prices']\n",
    "predictions_df['actual_value_ewma'] = pd.ewma(predictions_df[\"actual_value\"], span=60, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changing column names\n",
    "predictions_df.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now plotting test predictions after smoothing\n",
    "predictions_plot = predictions_df.plot(title='Random Forest predicted prices 8-2 years after aligning & smoothing')\n",
    "predictions_plot.set_xlabel(\"Dates\")\n",
    "predictions_plot.set_ylabel(\"Stock Prices\")\n",
    "fig = predictions_plot.get_figure()\n",
    "fig.savefig(\"graphs/random forest after smoothing.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting just predict and actual average curves\n",
    "predictions_df_average = predictions_df[['average_predicted_price', 'average_actual_price']]\n",
    "predictions_plot = predictions_df_average.plot(title='Random Forest 8-2 years after aligning & smoothing')\n",
    "predictions_plot.set_xlabel(\"Dates\")\n",
    "predictions_plot.set_ylabel(\"Stock Prices\")\n",
    "fig = predictions_plot.get_figure()\n",
    "fig.savefig(\"graphs/random forest after smoothing 2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing the prices by a constant value so that it represents closing price during the testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def offset_value(test_start_date, test, predictions_df):\n",
    "    temp_date = test_start_date\n",
    "    average_last_5_days_test = 0\n",
    "    average_upcoming_5_days_predicted = 0\n",
    "    total_days = 10\n",
    "    for i in range(total_days):\n",
    "        average_last_5_days_test += test.loc[temp_date, 'prices']\n",
    "        temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "        difference = temp_date + timedelta(days=1)\n",
    "        temp_date = difference.strftime('%Y-%m-%d')\n",
    "    average_last_5_days_test = average_last_5_days_test / total_days\n",
    "\n",
    "    temp_date = test_start_date\n",
    "    for i in range(total_days):\n",
    "        average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "        temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "        difference = temp_date + timedelta(days=1)\n",
    "        temp_date = difference.strftime('%Y-%m-%d')\n",
    "    average_upcoming_5_days_predicted = average_upcoming_5_days_predicted / total_days\n",
    "    difference_test_predicted_prices = average_last_5_days_test - average_upcoming_5_days_predicted\n",
    "    return difference_test_predicted_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "# # Converting string to date time\n",
    "# temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "# # Adding one day from date time\n",
    "# difference = temp_date + timedelta(days=1)\n",
    "# # Converting again date time to string\n",
    "# temp_date = difference.strftime('%Y-%m-%d')\n",
    "        \n",
    "# start_year = datetime.strptime(train_start_date, \"%Y-%m-%d\").date().month\n",
    "\n",
    "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "prediction_list = []\n",
    "for year in years:\n",
    "    # Splitting the training and testing data\n",
    "    train_start_date = str(year) + '-01-01'\n",
    "    train_end_date = str(year) + '-10-31'\n",
    "    test_start_date = str(year) + '-11-01'\n",
    "    test_end_date = str(year) + '-12-31'\n",
    "    train = df.ix[train_start_date : train_end_date]\n",
    "    test = df.ix[test_start_date:test_end_date]\n",
    "    \n",
    "    # Calculating the sentiment score\n",
    "    sentiment_score_list = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_train = np.asarray(sentiment_score_list)\n",
    "    sentiment_score_list = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_test = np.asarray(sentiment_score_list)\n",
    "    \n",
    "    # Generating models\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(numpy_df_train, train['prices'])\n",
    "    \n",
    "\n",
    "    prediction = lr.predict(numpy_df_test)\n",
    "    prediction_list.append(prediction)\n",
    "    #print train_start_date + ' ' + train_end_date + ' ' + test_start_date + ' ' + test_end_date\n",
    "    idx = pd.date_range(test_start_date, test_end_date)\n",
    "    #print year\n",
    "    predictions_df_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "    \n",
    "    difference_test_predicted_prices = offset_value(test_start_date, test, predictions_df_list)\n",
    "    # Adding offset to all the advpredictions_df price values\n",
    "    predictions_df_list['prices'] = predictions_df_list['prices'] + difference_test_predicted_prices\n",
    "    predictions_df_list\n",
    "\n",
    "    # Smoothing the plot\n",
    "    predictions_df_list['ewma'] = pd.ewma(predictions_df_list[\"prices\"], span=10, freq=\"D\")\n",
    "    predictions_df_list['actual_value'] = test['prices']\n",
    "    predictions_df_list['actual_value_ewma'] = pd.ewma(predictions_df_list[\"actual_value\"], span=10, freq=\"D\")\n",
    "    # Changing column names\n",
    "    predictions_df_list.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']\n",
    "    predictions_df_list.plot()\n",
    "    predictions_df_list_average = predictions_df_list[['average_predicted_price', 'average_actual_price']]\n",
    "    predictions_df_list_average.plot()\n",
    "    \n",
    "#     predictions_df_list.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "# # Converting string to date time\n",
    "# temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "# # Adding one day from date time\n",
    "# difference = temp_date + timedelta(days=1)\n",
    "# # Converting again date time to string\n",
    "# temp_date = difference.strftime('%Y-%m-%d')\n",
    "        \n",
    "# start_year = datetime.strptime(train_start_date, \"%Y-%m-%d\").date().month\n",
    "\n",
    "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "prediction_list = []\n",
    "for year in years:\n",
    "    # Splitting the training and testing data\n",
    "    train_start_date = str(year) + '-01-01'\n",
    "    train_end_date = str(year) + '-10-31'\n",
    "    test_start_date = str(year) + '-11-01'\n",
    "    test_end_date = str(year) + '-12-31'\n",
    "    train = df.ix[train_start_date : train_end_date]\n",
    "    test = df.ix[test_start_date:test_end_date]\n",
    "    \n",
    "    # Calculating the sentiment score\n",
    "    sentiment_score_list = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentim ent_score_list.append(sentiment_score)\n",
    "    numpy_df_train = np.asarray(sentiment_score_list)\n",
    "    sentiment_score_list = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_test = np.asarray(sentiment_score_list)\n",
    "    \n",
    "    # Generating models\n",
    "    rf = RandomForestRegressor(random_state=)\n",
    "    rf.fit(numpy_df_train, train['prices'])\n",
    "    #print rf\n",
    "    \n",
    "    prediction, bias, contributions = ti.predict(rf, numpy_df_test)\n",
    "    prediction_list.append(prediction)\n",
    "    #print train_start_date + ' ' + train_end_date + ' ' + test_start_date + ' ' + test_end_date\n",
    "    idx = pd.date_range(test_start_date, test_end_date)\n",
    "    #print year\n",
    "    predictions_df_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "    \n",
    "    difference_test_predicted_prices = offset_value(test_start_date, test, predictions_df_list)\n",
    "    # Adding offset to all the advpredictions_df price values\n",
    "    predictions_df_list['prices'] = predictions_df_list['prices'] + difference_test_predicted_prices\n",
    "    predictions_df_list\n",
    "\n",
    "    # Smoothing the plot\n",
    "    predictions_df_list['ewma'] = pd.ewma(predictions_df_list[\"prices\"], span=10, freq=\"D\")\n",
    "    predictions_df_list['actual_value'] = test['prices']\n",
    "    predictions_df_list['actual_value_ewma'] = pd.ewma(predictions_df_list[\"actual_value\"], span=10, freq=\"D\")\n",
    "    # Changing column names\n",
    "    predictions_df_list.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']\n",
    "    predictions_df_list.plot()\n",
    "    predictions_df_list_average = predictions_df_list[['average_predicted_price', 'average_actual_price']]\n",
    "    predictions_df_list_average.plot()\n",
    "    \n",
    "#     predictions_df_list.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image  \n",
    "# dot_data = tree.export_graphviz(rf, out_file=None, \n",
    "#                      feature_names=['comp', 'neg', 'neu', 'pos'],  \n",
    "#                      class_names=iris.target_names,  \n",
    "#                      filled=True, rounded=True,  \n",
    "#                      special_characters=True)  \n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "# # Converting string to date time\n",
    "# temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "# # Adding one day from date time\n",
    "# difference = temp_date + timedelta(days=1)\n",
    "# # Converting again date time to string\n",
    "# temp_date = difference.strftime('%Y-%m-%d')\n",
    "        \n",
    "# start_year = datetime.strptime(train_start_date, \"%Y-%m-%d\").date().month\n",
    "\n",
    "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "prediction_list = []\n",
    "for year in years:\n",
    "    # Splitting the training and testing data\n",
    "    train_start_date = str(year) + '-01-01'\n",
    "    train_end_date = str(year) + '-10-31'\n",
    "    test_start_date = str(year) + '-11-01'\n",
    "    test_end_date = str(year) + '-12-31'\n",
    "    train = df.ix[train_start_date : train_end_date]\n",
    "    test = df.ix[test_start_date:test_end_date]\n",
    "    \n",
    "    # Calculating the sentiment score\n",
    "    sentiment_score_list = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_train = np.asarray(sentiment_score_list)\n",
    "    sentiment_score_list = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_test = np.asarray(sentiment_score_list)\n",
    "    \n",
    "    # Generating models\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False) # span = 20 # best 1\n",
    "    mlpc.fit(numpy_df_train, train['prices'])   \n",
    "    prediction = mlpc.predict(numpy_df_test)\n",
    "    \n",
    "    prediction_list.append(prediction)\n",
    "    #print train_start_date + ' ' + train_end_date + ' ' + test_start_date + ' ' + test_end_date\n",
    "    idx = pd.date_range(test_start_date, test_end_date)\n",
    "    #print year\n",
    "    predictions_df_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "    \n",
    "    difference_test_predicted_prices = offset_value(test_start_date, test, predictions_df_list)\n",
    "    # Adding offset to all the advpredictions_df price values\n",
    "    predictions_df_list['prices'] = predictions_df_list['prices'] + difference_test_predicted_prices\n",
    "    predictions_df_list\n",
    "\n",
    "    # Smoothing the plot\n",
    "    predictions_df_list['ewma'] = pd.ewma(predictions_df_list[\"prices\"], span=20, freq=\"D\")\n",
    "    predictions_df_list['actual_value'] = test['prices']\n",
    "    predictions_df_list['actual_value_ewma'] = pd.ewma(predictions_df_list[\"actual_value\"], span=20, freq=\"D\")\n",
    "    # Changing column names\n",
    "    predictions_df_list.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']\n",
    "    predictions_df_list.plot()\n",
    "    predictions_df_list_average = predictions_df_list[['average_predicted_price', 'average_actual_price']]\n",
    "    predictions_df_list_average.plot()\n",
    "    \n",
    "#     predictions_df_list.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='tanh', \n",
    "                         solver='lbfgs', alpha=0.010, learning_rate_init = 0.001, shuffle=False)\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.010, learning_rate_init = 0.001, shuffle=False) # span = 20\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False) # span = 20 # best 1\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 50), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking the performance of training data itself\n",
    "prediction, bias, contributions = ti.predict(rf, numpy_df_train)\n",
    "idx = pd.date_range(train_start_date, train_end_date)\n",
    "predictions_df1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "predictions_df1.plot() \n",
    "train['prices'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
